{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Songs Analysis - Data Exploration\n",
    "\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path for custom modules\n",
    "sys.path.append('../src')\n",
    "from data_processing import load_raw, normalize_columns, basic_clean, save_clean\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path('../data')\n",
    "RAW_DATA_PATH = DATA_DIR / 'raw' / 'spotify_songs.csv'\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load data with fallback options\n",
    "def load_dataset():\n",
    "    \"\"\"Load dataset with multiple fallback options\"\"\"\n",
    "    possible_files = [\n",
    "        'spotify_songs.csv',\n",
    "        'SpotifyFeatures.csv', \n",
    "        'tracks.csv',\n",
    "        'data.csv'\n",
    "    ]\n",
    "    \n",
    "    for filename in possible_files:\n",
    "        file_path = DATA_DIR / 'raw' / filename\n",
    "        if file_path.exists():\n",
    "            print(f\"Loading data from: {file_path}\")\n",
    "            return load_raw(file_path)\n",
    "    \n",
    "    # If no local file found, try to download from URL\n",
    "    try:\n",
    "        print(\"No local file found. Attempting to download from URL...\")\n",
    "        url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv\"\n",
    "        df = pd.read_csv(url)\n",
    "        # Save a local copy\n",
    "        DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        (DATA_DIR / 'raw').mkdir(exist_ok=True)\n",
    "        df.to_csv(DATA_DIR / 'raw' / 'spotify_songs.csv', index=False)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        # Create sample data for demonstration\n",
    "        print(\"Creating sample data for demonstration...\")\n",
    "        return create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"Create sample data if no dataset is available\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    data = {\n",
    "        'track_name': [f'Song_{i}' for i in range(n_samples)],\n",
    "        'artist_name': [f'Artist_{np.random.randint(1, 50)}' for _ in range(n_samples)],\n",
    "        'playlist_genre': np.random.choice(['Pop', 'Rock', 'Hip-Hop', 'Jazz', 'Classical', 'Electronic'], n_samples),\n",
    "        'danceability': np.random.uniform(0, 1, n_samples),\n",
    "        'energy': np.random.uniform(0, 1, n_samples),\n",
    "        'loudness': np.random.uniform(-20, 0, n_samples),\n",
    "        'acousticness': np.random.uniform(0, 1, n_samples),\n",
    "        'instrumentalness': np.random.exponential(0.1, n_samples),\n",
    "        'liveness': np.random.uniform(0, 1, n_samples),\n",
    "        'valence': np.random.uniform(0, 1, n_samples),\n",
    "        'tempo': np.random.uniform(60, 200, n_samples),\n",
    "        'duration_ms': np.random.randint(120000, 360000, n_samples),\n",
    "        'popularity': np.random.randint(0, 101, n_samples)\n",
    "    }\n",
    "    \n",
    "    # Cap instrumentalness at 1\n",
    "    data['instrumentalness'] = np.minimum(data['instrumentalness'], 1)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load the data\n",
    "df = load_dataset()\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial inspection\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize column names\n",
    "df_clean = normalize_columns(df)\n",
    "print(\"Column names after normalization:\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "missing_data = df_clean.isnull().sum()\n",
    "missing_percent = (missing_data / len(df_clean)) * 100\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "display(missing_info[missing_info['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Basic cleaning\n",
    "df_clean = basic_clean(df_clean)\n",
    "print(f\"Shape after basic cleaning: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation - check ranges for audio features\n",
    "def validate_audio_features(df):\n",
    "    \"\"\"Validate that audio features are within expected ranges\"\"\"\n",
    "    features_ranges = {\n",
    "        'danceability': (0, 1),\n",
    "        'energy': (0, 1),\n",
    "        'acousticness': (0, 1),\n",
    "        'instrumentalness': (0, 1),\n",
    "        'liveness': (0, 1),\n",
    "        'valence': (0, 1),\n",
    "        'popularity': (0, 100)\n",
    "    }\n",
    "    \n",
    "    print(\"Data validation results:\")\n",
    "    for feature, (min_val, max_val) in features_ranges.items():\n",
    "        if feature in df.columns:\n",
    "            invalid = ~df[feature].between(min_val, max_val)\n",
    "            if invalid.any():\n",
    "                print(f\"  {feature}: {invalid.sum()} values outside range [{min_val}, {max_val}]\")\n",
    "            else:\n",
    "                print(f\"  {feature}: All values within expected range\")\n",
    "\n",
    "validate_audio_features(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter unrealistic values\n",
    "print(\"Filtering unrealistic values...\")\n",
    "initial_shape = df_clean.shape\n",
    "\n",
    "# Filter based on duration (reasonable song length)\n",
    "if 'duration_ms' in df_clean.columns:\n",
    "    df_clean = df_clean[(df_clean['duration_ms'] >= 30000) & (df_clean['duration_ms'] <= 600000)]\n",
    "\n",
    "# Filter tempo (reasonable BPM range)\n",
    "if 'tempo' in df_clean.columns:\n",
    "    df_clean = df_clean[(df_clean['tempo'] >= 40) & (df_clean['tempo'] <= 240)]\n",
    "\n",
    "print(f\"Rows removed: {initial_shape[0] - df_clean.shape[0]}\")\n",
    "print(f\"Final shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Statistics and Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical features\n",
    "numerical_features = ['danceability', 'energy', 'loudness', 'acousticness', \n",
    "                     'instrumentalness', 'liveness', 'valence', 'tempo', \n",
    "                     'duration_ms', 'popularity']\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "available_numerical = [col for col in numerical_features if col in df_clean.columns]\n",
    "\n",
    "print(\"Descriptive statistics for numerical features:\")\n",
    "display(df_clean[available_numerical].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "categorical_columns = []\n",
    "for col in ['playlist_genre', 'genre']:\n",
    "    if col in df_clean.columns:\n",
    "        categorical_columns.append(col)\n",
    "\n",
    "if categorical_columns:\n",
    "    print(\"Categorical features value counts:\")\n",
    "    for col in categorical_columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        display(df_clean[col].value_counts().head(10))\n",
    "else:\n",
    "    print(\"No categorical columns found with expected names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SQL Analysis with SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in-memory SQLite database\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Save dataframe to SQL\n",
    "df_clean.to_sql('spotify_songs', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Example 1: Average audio features by genre\n",
    "if 'playlist_genre' in df_clean.columns:\n",
    "    query1 = \"\"\"\n",
    "    SELECT playlist_genre,\n",
    "           COUNT(*) as song_count,\n",
    "           AVG(danceability) as avg_danceability,\n",
    "           AVG(energy) as avg_energy,\n",
    "           AVG(valence) as avg_valence,\n",
    "           AVG(popularity) as avg_popularity\n",
    "    FROM spotify_songs\n",
    "    GROUP BY playlist_genre\n",
    "    ORDER BY avg_popularity DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    genre_stats = pd.read_sql_query(query1, conn)\n",
    "    print(\"Average audio features by genre:\")\n",
    "    display(genre_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Popularity distribution analysis\n",
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN popularity < 40 THEN 'Low (0-39)'\n",
    "        WHEN popularity BETWEEN 40 AND 60 THEN 'Medium (40-60)'\n",
    "        ELSE 'High (61-100)'\n",
    "    END as popularity_category,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(AVG(danceability), 3) as avg_danceability,\n",
    "    ROUND(AVG(energy), 3) as avg_energy,\n",
    "    ROUND(AVG(acousticness), 3) as avg_acousticness\n",
    "FROM spotify_songs\n",
    "GROUP BY popularity_category\n",
    "ORDER BY \n",
    "    CASE popularity_category\n",
    "        WHEN 'Low (0-39)' THEN 1\n",
    "        WHEN 'Medium (40-60)' THEN 2\n",
    "        WHEN 'High (61-100)' THEN 3\n",
    "    END\n",
    "\"\"\"\n",
    "\n",
    "popularity_stats = pd.read_sql_query(query2, conn)\n",
    "print(\"Popularity category analysis:\")\n",
    "display(popularity_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: High energy songs analysis\n",
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    playlist_genre,\n",
    "    COUNT(*) as total_songs,\n",
    "    SUM(CASE WHEN energy > 0.8 THEN 1 ELSE 0 END) as high_energy_songs,\n",
    "    ROUND(SUM(CASE WHEN energy > 0.8 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as high_energy_percentage\n",
    "FROM spotify_songs\n",
    "WHERE playlist_genre IS NOT NULL\n",
    "GROUP BY playlist_genre\n",
    "ORDER BY high_energy_percentage DESC\n",
    "\"\"\"\n",
    "\n",
    "energy_analysis = pd.read_sql_query(query3, conn)\n",
    "print(\"High energy songs by genre:\")\n",
    "display(energy_analysis)\n",
    "\n",
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "save_clean(df_clean, 'clean_spotify.csv')\n",
    "print(\"Cleaned dataset saved successfully!\")\n",
    "\n",
    "# Final dataset info\n",
    "print(f\"\\nFinal cleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Columns in cleaned dataset: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization of popularity distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_clean['popularity'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Popularity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Song Popularity')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData exploration completed successfully!\")\n",
    "print(\"Next step: Run 02_feature_analysis.ipynb for detailed feature analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}